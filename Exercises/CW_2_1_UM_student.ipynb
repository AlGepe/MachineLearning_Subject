{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we start the exercise\n",
    "* we need to make sure that we have the current version of the sklearn library. The script is prepared for version 0.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version has been installed: 0.19.1.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version has been installed: {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In OKWF, you will need to install a local environment as described:\n",
    "\n",
    "https://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/konfiguracja\n",
    "\n",
    "It will also be useful for further activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import diag, interp\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Cross-validation\n",
    "* In this exercise, we will look at how measures of the classifier's quality depend on the proportion of classes in the training set and the size of the training set\n",
    "* The regression will still be logistic regression, but this time we will start using the library version from the module [scikit-learn](http://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for generating data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen(ile):\n",
    "    mu = [(-1,0.5),(1.2,4)] # secondary classes\n",
    "    cov = [diag([3,3]), diag([4,1.7])] # covariance matrices for classes\n",
    "    \n",
    "    X = np.zeros((ile*len(mu), 2)) # space for input data\n",
    "    Y = np.zeros((ile*len(mu), 1),dtype = int) # space for output\n",
    "    for klasa in range(len(mu)):\n",
    "        X[klasa*ile:(klasa+1)*ile] = np.random.multivariate_normal(mu[klasa],cov[klasa],ile)\n",
    "        Y[klasa*ile:(klasa+1)*ile] = klasa\n",
    "    Y = Y.ravel()\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test this function, we generate 50 examples, we print the first 5, we draw all of them using the function `scatter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y = gen(50)\n",
    "print('X: ', X[0:5,:])\n",
    "print('Y: ', Y[0:5])\n",
    "plt.scatter(X[:,0], X[:,1] ,c = Y, cmap=plt.cm.Set1, alpha =0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasy równoliczne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us observe the variability of the classifier quality measures when selecting subsets for learning and testing from the training set.\n",
    "* we will use the function to divide the set [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "* we will use functions from the module to calculate quality measures [sklearn.metrics](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n",
    "Complete the training file so that the test set is 20% of the entire training set. Illustrate the points belonging to the teaching part and dio of the test part with `scatter`:\n",
    "\n",
    "* Breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ilustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,0], X_train[:,1], c = y_train, cmap=plt.cm.Set1, alpha =0.5)\n",
    "plt.scatter(X_test[:,0] , X_test[:,1],  c = y_test,  cmap=plt.cm.Set1, alpha =0.5, marker = '*' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is implemented in the class ['LogisticRegression'](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). We create an instance of this class object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We teach it on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform predictions for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effects can be viewed using a matrix of errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print('TN: ',tn,'FP: ', fp, 'FN: ', fn, 'TP: ', tp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the loop, we repeat the process of dividing the training set and for each division we calculate the quality measures:\n",
    "* positive precision: (positive predictive value (PPV), precision). He answers the question: \"If the test result is positive, what is the probability that the subject is ill?\"\n",
    "\n",
    "$ \\qquad $ $ PPV = \\frac {TP} {P '} = \\frac {TP} {TP + FP} $\n",
    "\n",
    "* sensitivity: The probability that the classification will be correct, provided the case is positive (True Positive Rate, Recall). This is, for example, the probability that a test made for a sick person shows that she is ill.\n",
    "\n",
    "$ \\qquad $ $ TPR = \\frac {TP} {P} = \\frac {TP} {TP + FN} $\n",
    "\n",
    "\n",
    "* Accuracy (accuracy (ACC)): Probability of correct classification.\n",
    "\n",
    "$ \\qquad $ $ ACC = \\frac {TP + TN} {P + N} $\n",
    "\n",
    "* F1-score: harmonic mean of precision and sensitivity:\n",
    "\n",
    "$ \\qquad $ $ F_1 = 2 \\frac {PPV \\cdot TPR} {PPV + TPR} = \\frac {2TP} {2TP + FP + FN} $\n",
    "This measure gives an assessment of the balance between sensitivity and precision. This measure does not include true negative results.\n",
    "\n",
    "* Matthews correlation coefficient (Matthews correlation coefficient):\n",
    "\n",
    "$ \\qquad $ $\n",
    "\\text {MCC} = \\frac {TP \\cdot TN - FP \\cdot FN} {\\sqrt {(TP + FP) (TP + FN) (TN + FP) (TN + FN)}}\n",
    "$\n",
    "\n",
    "  * This ratio takes into account both true and false positive and negative results and is generally considered as a balanced measure that can be applied even when classes are of very different sizes.\n",
    "  * MCC is in fact the correlation coefficient between observed and predicted binary classifications; returns a value from -1 to +1.\n",
    "    * The +1 ratio corresponds to the ideal classification,\n",
    "    * 0 no better than random assignment of result and\n",
    "    * -1 means a total disagreement between the classification and the actual state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = ... # create an instance of the classifier\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = ... # podziel zbiór z 20% do testowania\n",
    "\n",
    "\n",
    "    ... # Train the classifier\n",
    "     y_pred = ... # do the prediction for the test set\n",
    "    \n",
    "    \n",
    "    PPV = metrics.precision_score(y_test, y_pred)\n",
    "    REC = metrics.recall_score(y_test, y_pred)\n",
    "    ACC = metrics.accuracy_score(y_test, y_pred)\n",
    "    F1 = metrics.f1_score(y_test, y_pred)\n",
    "    MCC = metrics.matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    print('PPV = {p:.3f} REC = {r:.3f} ACC = {a:.3f} F1 = {f:.3f} MCC =  {m:.3f}  '.format(a=ACC,f=F1,m=MCC,p=PPV,r=REC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the measures change with each draw.\n",
    "\n",
    "Most often, not such random divisions are used, but a systematic 'k-fold cross-validation' distribution. The procedure looks like this:\n",
    "* We divide the teaching set (X and y) into equal parts\n",
    "* We put aside the 1st part as test data,\n",
    "* We teach the classifier on the remaining `k-1` parts\n",
    "* We calculate the quality measures on this reserved part\n",
    "* Select the 2nd part as test data\n",
    "* We teach the classifier on the remaining `k-1` parts\n",
    "* We calculate the quality measures on this reserved part\n",
    "* $ \\vdots $\n",
    "\n",
    "In the `sklearn` library we have the convenient` cross_val_score` function for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppv = cross_val_score(lr, X, Y, cv=10, scoring='precision')\n",
    "print('PPV = {0:.2f} +/- {1:.2f}'.format(ppv.mean(),ppv.std()))\n",
    "rec = cross_val_score(lr, X, Y, cv=10, scoring='recall')\n",
    "print('REC = {0:.2f} +/- {1:.2f}'.format(rec.mean(),rec.std()))\n",
    "acc = cross_val_score(lr, X, Y, cv=10, scoring='accuracy')\n",
    "print('ACC = {0:.2f} +/- {1:.2f}'.format(acc.mean(),acc.std()))\n",
    "f1 = cross_val_score(lr, X, Y, cv=10, scoring='f1')\n",
    "print('F1 = {0:.2f} +/- {1:.2f}'.format(f1.mean(),f1.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the set, let's examine the ROC curve. This time we will also use library functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf  = StratifiedKFold(n_splits=6)\n",
    "lr = LogisticRegression()\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "i = 0\n",
    "for train, test in skf.split(X, Y):\n",
    "    lr.fit(X[train], Y[train]) # Fit the regression(?)\n",
    "    probas_ = lr.predict_proba(X[test]) # we calculate the probabilities of belonging to test examples\n",
    "                                         # to classes by learned classifier\n",
    "                                         # (it returns in the given row the probability set for each of the possible classes)\n",
    "   \n",
    "    # We calculate the points of the ROC curve\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(Y[test], probas_[:, 1]) # in relation to the probability of class 1\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    # and the area under the curve\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    # we draw a curve \n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC dla podziału %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Losowa klasa', alpha=.8)\n",
    "# below summary: counting of mean and standard deviations, shading of the confidence interval\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Średni ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the quality measures from the size of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "PPV_mean = np.zeros((N,1))\n",
    "PPV_std = np.zeros((N,1))\n",
    "REC_mean = np.zeros((N,1))\n",
    "REC_std = np.zeros((N,1))\n",
    "ACC_mean = np.zeros((N,1))\n",
    "ACC_std = np.zeros((N,1))\n",
    "F1_mean = np.zeros((N,1))\n",
    "F1_std = np.zeros((N,1))\n",
    "\n",
    "n= 30+np.floor(np.logspace(1,4,N)).astype(int)\n",
    "\n",
    "for i in range(N):\n",
    "    X,Y = gen(int(n[i]))\n",
    "    lr = LogisticRegression()\n",
    "    ppv = ...\n",
    "    PPV_mean[i] =ppv.mean()\n",
    "    PPV_std[i]  = ppv.std()\n",
    "    rec = ...\n",
    "    REC_mean[i]  = rec.mean()\n",
    "    REC_std[i]  = rec.std()\n",
    "    acc = ...\n",
    "    ACC_mean[i]  = acc.mean()\n",
    "    ACC_std[i]  = acc.std()\n",
    "    f1 = ...\n",
    "    F1_mean[i]  = f1.mean()\n",
    "    F1_std[i]  = f1.std()\n",
    "\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.errorbar(n,PPV_mean,yerr=PPV_std)\n",
    "plt.errorbar(n+2,REC_mean,yerr=REC_std)\n",
    "plt.errorbar(n+4,ACC_mean,yerr=ACC_std)\n",
    "plt.errorbar(n+6,F1_mean,yerr=F1_std)\n",
    "plt.legend(('PPV','REC','ACC','F1'))\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|## Unbalanced classes\n",
    "We will now create data in which one of the classes is M-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_rozne(ile, M):\n",
    "    mu = [(-1,0.5),(1,4)]\n",
    "    #mu = [(-1,0.5),(-1,0.5)]\n",
    "    cov = [diag([1.7,1.8]), diag([1.5,0.7])]\n",
    "    X = np.zeros(((M+1)*ile, 2)) # space for input data\n",
    "    Y = np.zeros(((M+1)*ile, 1),dtype = int) # space for output\n",
    "    print(Y.shape)\n",
    "    klasa = 0\n",
    "    X[0:ile] = np.random.multivariate_normal(mu[klasa],cov[klasa],ile)\n",
    "    Y[0:ile] = klasa\n",
    "    klasa =1 \n",
    "    X[ile:ile+ile*M] = np.random.multivariate_normal(mu[klasa],cov[klasa],ile*M)\n",
    "    Y[ile:ile+ile*M] = klasa\n",
    "    Y = Y.ravel()\n",
    "    print(np.sum(Y==0), np.sum(Y==1) )\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are watching data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y = gen_rozne(30,100)\n",
    "plt.scatter ...\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate quality measures for unbalanced data with a 10-fold split. Note the difference in the values of the first 4 measures and measures of the MCC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppv = ...\n",
    "print('PPV = {0:.2f} +/- {1:.2f}'.format(ppv.mean(),ppv.std()))\n",
    "rec = ...\n",
    "print('REC = {0:.2f} +/- {1:.2f}'.format(rec.mean(),rec.std()))\n",
    "acc = ...\n",
    "print('ACC = {0:.2f} +/- {1:.2f}'.format(acc.mean(),acc.std()))\n",
    "f1 = ...\n",
    "print('F1 = {0:.2f} +/- {1:.2f}'.format(f1.mean(),f1.std()))\n",
    "print('-----')\n",
    "MCC=np.zeros((10,1))\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=...) # 10% test to be similar to a 10-fold split\n",
    "     ... # train the model\n",
    "    y_pred = ... # prediction for the test set\n",
    "    MCC[i] = metrics.matthews_corrcoef(y_test, y_pred)\n",
    "print('MCC = {0:.2f} +/- {1:.2f}'.format(MCC.mean(),MCC.std()))  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to see if it can be improved if in the divisions, take care to preserve the proportions of classes. This can be easily done using the `StratifiedKFold` function, it returns indexes to the training and test inventory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "for train, test in skf.split(X, Y):  \n",
    "    lr.fit(X[train,:],Y[train])\n",
    "    y_pred = lr.predict(X[test,:]) \n",
    "    y_test = Y[test]\n",
    "    PPV = metrics.precision_score(y_test, y_pred)\n",
    "    REC = metrics.recall_score(y_test, y_pred)\n",
    "    ACC = metrics.accuracy_score(y_test, y_pred)\n",
    "    F1 = metrics.f1_score(y_test, y_pred)\n",
    "    MCC = metrics.matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    print('PPV = {p:.3f} REC = {r:.3f} ACC = {a:.3f} F1 = {f:.3f} MCC =  {m:.3f}  '.format(a=ACC,f=F1,m=MCC,p=PPV,r=REC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the ROC curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf  = StratifiedKFold(n_splits=6)\n",
    "lr = LogisticRegression()\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "i = 0\n",
    "for train, test in skf .split(X, Y):\n",
    "    ... # we fit the data (?)\n",
    "    probas_ = ...# we calculate the probabilities of belonging to test examples\n",
    "                                         # to classes by learned classifier\n",
    "                                         # (it returns in the given row the probability set for each of the possible classes)\n",
    "    # We calculate the points of the ROC curve\n",
    "    fpr, tpr, thresholds = ... # in relation to the probability of class 1\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    # and area under the curve\n",
    "    roc_auc = ...\n",
    "    aucs.append(roc_auc)\n",
    "    # we draw a curve\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC dla podziału %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Losowa klasa', alpha=.8)\n",
    "# below summary: counting of mean and standard deviations, shading of the confidence interval\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Średni ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above calculation calculations should be carried out for classes whose differences clearly differ and for those that overlap to a significant extent. It is necessary to replace the average classes in the function generating differential data.\n",
    "\n",
    "## What's the result of the application?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
